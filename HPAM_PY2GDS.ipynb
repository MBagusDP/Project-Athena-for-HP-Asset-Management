{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python X Google Sheet\n",
    "\n",
    "This notebook demonstrate on how we can connect python to a google sheet to enable connection to google data studio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establishing connection with google drive and google sheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Import packages*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gspread\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Connect to google service account*\n",
    "\n",
    "Follow https://docs.gspread.org/en/latest/oauth2.html guide on how to enable API acces for a project in google developer cloud by using service account. The .json file is generated from there. After obtaining the .json file, the next step would be to create an empty sheet in a desired location in our google drive for later to be opened with python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gc = gspread.service_account(filename=\"credential_keys/personal_credential.json\")\n",
    "sh = gc.open(\"Your google sheet name here\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Get all record from google sheet*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(sh.sheet1.get_all_records()).sort_values(\"created_at\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uploading python dataframe to google sheet\n",
    "\n",
    "#### *Create dataframe*\n",
    "\n",
    "in this case, I will just load a dataframe from my local drive just for demonstration purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"PROMS_API_\" + str(datetime.date(datetime.now())) + \".csv\").drop(columns=\"time_input\")\n",
    "df.created_at = pd.to_datetime(df.created_at)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gs_df = pd.DataFrame(sh.sheet1.get_all_records())\n",
    "# gs_df.created_at = pd.to_datetime(gs_df.created_at)\n",
    "gs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Removing empty values*\n",
    "\n",
    "Google sheet does not understand empty values, thus it will not allow us to upload a dataframe which contains empty values. We could replace empty values with \"\" or just remove them entirely like I did below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time_input            107627\n",
       "title                      0\n",
       "remarks                    0\n",
       "time_to_completion         0\n",
       "complexity                 0\n",
       "related_parties            0\n",
       "score                      0\n",
       "created_at                 0\n",
       "created_by                 0\n",
       "division                   0\n",
       "word_count                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: this part is where we have to be sure to know what we should do with the empty data which will also change the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['title',\n",
       " 'remarks',\n",
       " 'time_to_completion',\n",
       " 'complexity',\n",
       " 'related_parties',\n",
       " 'score',\n",
       " 'created_at',\n",
       " 'created_by',\n",
       " 'division',\n",
       " 'word_count']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns=[\"time_input\"])\n",
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Upload dataframe to google sheet*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'spreadsheetId': '1oximbVCuAvbmcHEvRnxonMLpTOSLJu0NsC6JGNTnEoM',\n",
       " 'updatedRange': 'Sheet1!A1:J117016',\n",
       " 'updatedRows': 117016,\n",
       " 'updatedColumns': 10,\n",
       " 'updatedCells': 1170160}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sh.sheet1.update([df.columns.values.tolist()] + df.values.tolist())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9c3e94b00770bcff0859a3b94b70bb82124582672ac7be88db2571f3b5004ac9"
  },
  "kernelspec": {
   "display_name": "athena",
   "language": "python",
   "name": "athena"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
