{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction of Job Classification by Manual Classification\n",
    "\n",
    "Classifying Jobs is quite a challenge, especially when we are dealing with large amount of reports. However, in this markdown, I would like to demonstrate how we can do a prediction for jobs and score based on the classified jobs that is manually categorized. Although we might have a better solution regarding Job Classification rather than manually determining which catergory a job report belongs to. We only care about the end result, which is the prediction.\n",
    "\n",
    "#### *Import packages*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics\n",
    "import nltk\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Import dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proms_df = pd.read_csv(\"CSV/PROMS_API_EXTRA.csv\")\n",
    "proms_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Text processing*\n",
    "\n",
    "As the HPAM_ATHENA.ipynb has explained about text processing, I will import the processed text and embed the text to the dataset to speed up the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "proms_df.title = pd.read_csv(\"Stemmed_Result/stemmed_title.txt\").title\n",
    "proms_df.remarks = pd.read_csv(\"Stemmed_Result/stemmed_remarks.txt\").remarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Checking empty values*\n",
    "\n",
    "Sometimes text processing creates empty values. The reason might be because of the text only contains noise (stopwords, punctuations, white space, etc). Ensuring that our data is free from null values is a must."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title                 2\n",
       "remarks               5\n",
       "time_to_completion    0\n",
       "complexity            0\n",
       "related_parties       0\n",
       "score                 0\n",
       "created_at            0\n",
       "office                0\n",
       "division              0\n",
       "word_count            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proms_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of empty values is apparently so little that it will not create any significant impact if we remove them. As such, I will remove the empty values.\n",
    "\n",
    "#### *Removing empty values*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "proms_df = proms_df[(proms_df.title.isnull() == False) & (proms_df.remarks.isnull() == False)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title                 0\n",
       "remarks               0\n",
       "time_to_completion    0\n",
       "complexity            0\n",
       "related_parties       0\n",
       "score                 0\n",
       "created_at            0\n",
       "office                0\n",
       "division              0\n",
       "word_count            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proms_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually Classifying Jobs\n",
    "\n",
    "With the help of Unigram and Bigram, we can determine which word or words oftenly used in our data. Thus we can decide which to name those jobs based on the Unigram and Bigram.\n",
    "\n",
    "#### *Counts of tasks*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(proms_df.title.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above, the top 3 tasks seems to be a call. If we take a closer look, we should not see any difference between \"call nasabah\" and \"calls\" as they are generally the same kind of job. This is the reason why we need to properly classify the jobs.\n",
    "\n",
    "#### *Unigram*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_title = pd.Series(np.concatenate(list(proms_df.title.str.split())))\n",
    "\n",
    "bahasaStopwords = StopWordRemoverFactory().get_stop_words()\n",
    "clean_tokenized_title = tokenized_title[~tokenized_title.isin(bahasaStopwords)]\n",
    "\n",
    "unigram_freq = pd.DataFrame(clean_tokenized_title).value_counts().sort_values(ascending=False)\n",
    "unigram_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Bigram*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = []\n",
    "for value in proms_df.title:\n",
    "    tokenized = value.split()\n",
    "    tokenized = [word for word in tokenized if word not in bahasaStopwords]\n",
    "    zipped = nltk.ngrams(tokenized, 2)\n",
    "    lst = []\n",
    "    for item in zipped:\n",
    "        lst.append(item)\n",
    "    bigram.extend(lst)\n",
    "\n",
    "bigram_freq = pd.DataFrame(bigram).value_counts().sort_values(ascending=False)\n",
    "bigram_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the unigram and bigram data counts above, we can determine which word or words is the most important and used it as the new task title.\n",
    "\n",
    "#### *Observing Unigrams*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "observe_call = pd.DataFrame(proms_df.loc[proms_df.title.str.contains(\"call\")].value_counts(\"title\")).reset_index()\n",
    "observe_hubung = pd.DataFrame(proms_df.loc[proms_df.title.str.contains(\"hubu\")].value_counts(\"title\").reset_index())\n",
    "observe_telpon = pd.DataFrame(proms_df.loc[(proms_df.title.str.contains(\"telp\")) | (proms_df.title.str.contains(\"tele\"))].value_counts(\"title\").reset_index())\n",
    "observe_meeting = pd.DataFrame(proms_df.loc[proms_df.title.str.contains(\"meeting\")].value_counts(\"title\")).reset_index()\n",
    "observe_transaction = pd.DataFrame(proms_df.loc[proms_df.title.str.contains(\"trans\")].value_counts(\"title\")).reset_index()\n",
    "observe_update = pd.DataFrame(proms_df.loc[proms_df.title.str.contains(\"update\")].value_counts(\"title\")).reset_index()\n",
    "observe_up = pd.DataFrame(proms_df.loc[proms_df.title.str.contains(\"up \")].value_counts(\"title\")).reset_index()\n",
    "observe_review = pd.DataFrame(proms_df.loc[proms_df.title.str.contains(\"review\")].value_counts(\"title\").reset_index())\n",
    "observe_prospek = pd.DataFrame(proms_df.loc[proms_df.title.str.contains(\"prosp\")].value_counts(\"title\").reset_index())\n",
    "observe_cl = pd.DataFrame(proms_df.loc[proms_df.title.str.contains(\"cl\")].value_counts(\"title\").reset_index())\n",
    "observe_data = pd.DataFrame(proms_df.loc[proms_df.title.str.contains(\"data\")].value_counts(\"title\").reset_index())\n",
    "observe_daily = pd.DataFrame(proms_df.loc[proms_df.title.str.contains(\"daily\")].value_counts(\"title\").reset_index())\n",
    "observe_siar = pd.DataFrame(proms_df.loc[proms_df.title.str.contains(\"siar\")].value_counts(\"title\").reset_index())\n",
    "observe_nav = pd.DataFrame(proms_df.loc[proms_df.title.str.contains(\"nav\")].value_counts(\"title\").reset_index())\n",
    "observe_end = pd.DataFrame(proms_df.loc[proms_df.title.str.contains(\"end of\")].value_counts(\"title\").reset_index())\n",
    "observe_siap = pd.DataFrame(proms_df.loc[proms_df.title.str.contains(\"siap\")].value_counts(\"title\").reset_index())\n",
    "observe_input = pd.DataFrame(proms_df.loc[proms_df.title.str.contains(\"input\")].value_counts(\"title\").reset_index())\n",
    "observe_surat = pd.DataFrame(proms_df.loc[proms_df.title.str.contains(\"surat\")].value_counts(\"title\").reset_index())\n",
    "observe_email = pd.DataFrame(proms_df.loc[proms_df.title.str.contains(\"email\")].value_counts(\"title\").reset_index())\n",
    "observe_nasabah = pd.DataFrame(proms_df.loc[proms_df.title.str.contains(\"nasabah\")].value_counts(\"title\").reset_index())\n",
    "observe_koordinasi = pd.DataFrame(proms_df.loc[proms_df.title.str.contains(\"koordinasi|kordinasi|coordination\")].value_counts(\"title\").reset_index())\n",
    "\n",
    "observe_call"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might be able to determine which word or words is the most important and change the title which falls under the same category with that title. However, we should make sure whether other tasks that is not on the same category also follows the same keyword. For example, we can see that keyword \"call\" also pull out \"concall\" which should not be in the same category as concall is supposed to be an online meeting and not a call.\n",
    "\n",
    "#### *Renaming tasks that falls into the same category*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\pandas\\core\\indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    }
   ],
   "source": [
    "proms_df.title.loc[(proms_df.title.str.contains(\"call|hubu|telp|tele|telf\")) &\n",
    "                   (~proms_df.title.str.contains(\"meeting|concall|video|conf|con call|extension|telegram|cek|lapor|\\\n",
    "                                                  review|setting|salur|bisa|surat|troubleshoot|mati|ubah|biaya|\\\n",
    "                                                  input|telecom|tagih|bank|cek\"))] = \"call\"\n",
    "proms_df.title.loc[proms_df.title.str.contains(\"meeting|concal|con call|video call|confere|confr|zoom\")] = \"meeting\"\n",
    "proms_df.title.loc[proms_df.title.str.contains(\"trans\")] = \"transaction\"\n",
    "proms_df.title.loc[(proms_df.title.str.contains(\"update\")) &\n",
    "                   (~proms_df.title.str.contains(\"saldo\"))] = \"update\"\n",
    "proms_df.title.loc[proms_df.title.str.contains(\"saldo\")] = \"balance\"\n",
    "proms_df.title.loc[(proms_df.title.str.contains(\"up\")) &\n",
    "                   (proms_df.title.str.contains(\"follow\"))] = \"follow-up\"\n",
    "proms_df.title.loc[proms_df.title.str.contains(\"visit|kunj\")] = \"visit\"\n",
    "proms_df.title.loc[(proms_df.title.str.contains(\"prospek|propek|prospect\")) &\n",
    "                   (~proms_df.title.str.contains(\"prospektus|prospectus\"))] = \"prospect\"\n",
    "proms_df.title.loc[(proms_df.title.str.contains(\"review\"))] = \"review\"\n",
    "proms_df.title.loc[(proms_df.title.str.contains(\"cl|confirmation letter\")) &\n",
    "                   (~proms_df.title.str.contains(\"cl[aiuoe]\"))] = \"confirmation-letter\"\n",
    "proms_df.title.loc[proms_df.title.str.contains(\"data\")] = \"data\"\n",
    "proms_df.title.loc[proms_df.title.str.contains(\"daily\")] = \"daily\"\n",
    "proms_df.title.loc[proms_df.title.str.contains(\"siar\")] = \"siar\"\n",
    "proms_df.title.loc[proms_df.title.str.contains(\"nav\")] = \"net-asset-value\"\n",
    "proms_df.title.loc[proms_df.title.str.contains(\"siap|eod|end of day\")] = \"siap\"\n",
    "proms_df.title.loc[proms_df.title.str.contains(\"input\")] = \"input\"\n",
    "proms_df.title.loc[proms_df.title.str.contains(\"surat|email\")] = \"mail\"\n",
    "proms_df.title.loc[proms_df.title.str.contains(\"koordinasi|kordinasi|coordination\")] = \"coordination\"\n",
    "proms_df.title.loc[~proms_df.title.isin([\"call\", \"meeting\",  \"transaction\", \"update\", \"balance\",\\\n",
    "                                         \"follow-up\", \"visit\", \"prospect\", \"review\", \"confirmation-letter\",\\\n",
    "                                         \"data\", \"daily\", \"siar\", \"net-asset-value\", \"siap\", \"input\",\\\n",
    "                                         \"mail\", \"coordination\"])] = \"other\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through Unigram, Bigram, and observation of the keywords, we can pull out tasks which falls into the same category to be renamed as the most general terms possible according to Unigram or Bigram. I decided to stop classifying the jobs on the 18th jobs and call the rest of uncategorized jobs as \"other\".\n",
    "\n",
    "#### *Percentage of classified jobs*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62.50164495328333"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classified = proms_df.loc[proms_df.title.isin([\"call\", \"meeting\",  \"transaction\", \"update\", \"balance\",\\\n",
    "                                               \"follow-up\", \"visit\", \"prospect\", \"review\", \"confirmation-letter\",\\\n",
    "                                               \"data\", \"daily\", \"siar\", \"net-asset-value\", \"siap\", \"input\",\\\n",
    "                                               \"mail\", \"coordination\"])].reset_index(drop=True).shape[0]\n",
    "\n",
    "unclassified = proms_df.loc[proms_df.title.isin([\"other\"])].shape[0]\n",
    "\n",
    "(classified/(classified+unclassified))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning\n",
    "\n",
    "We might be able to predict score directly by training our machine learning using score as the target. However, the large range or the score (from 1 to a 100) creates too many target to train our machine learning. This is why we classify jobs before we predict scores. by separating data based on the job category, we can reduce the amount of target that our machine learning has to learn and create a more accurate prediction.\n",
    "\n",
    "#### *Train and test for classifying jobs*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(proms_df.loc[:, proms_df.columns != \"title\"], \n",
    "proms_df.title, test_size=0.2, random_state=126)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Machine learning for classifying jobs*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "===========================\n",
      "Accuracy 0.7645455399943604\n",
      "===========================\n",
      "\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "            balance       0.93      0.96      0.94       841\n",
      "               call       0.66      0.86      0.74      2163\n",
      "confirmation-letter       0.85      0.99      0.91       697\n",
      "       coordination       0.51      0.43      0.47       201\n",
      "              daily       0.78      0.91      0.84       439\n",
      "               data       0.68      0.66      0.67       486\n",
      "          follow-up       0.64      0.79      0.70       890\n",
      "              input       0.85      0.72      0.78       387\n",
      "               mail       0.57      0.70      0.63       418\n",
      "            meeting       0.59      0.84      0.69      1492\n",
      "    net-asset-value       1.00      0.94      0.97       323\n",
      "              other       0.85      0.67      0.75      7952\n",
      "           prospect       0.79      0.78      0.78       230\n",
      "             review       0.76      0.80      0.78       817\n",
      "               siap       0.95      0.70      0.81       254\n",
      "               siar       0.92      0.90      0.91       313\n",
      "        transaction       0.86      0.85      0.86      1488\n",
      "             update       0.82      0.83      0.83      1244\n",
      "              visit       0.55      0.57      0.56       643\n",
      "\n",
      "           accuracy                           0.76     21278\n",
      "          macro avg       0.77      0.78      0.77     21278\n",
      "       weighted avg       0.78      0.76      0.77     21278\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vect_title = CountVectorizer(min_df=5, ngram_range=(1,5)).fit(x_train.remarks)\n",
    "\n",
    "model_naive_title = MultinomialNB()\n",
    "model_naive_title.fit(vect_title.transform(x_train.remarks), y_train)\n",
    "\n",
    "pred_title = model_naive_title.predict(vect_title.transform(x_test.remarks))\n",
    "\n",
    "print(\"Classification Report\")\n",
    "print(\"===========================\")\n",
    "print(\"Accuracy\", metrics.accuracy_score(y_test, pred_title))\n",
    "print(\"===========================\\n\")\n",
    "print(metrics.classification_report(y_test, pred_title, labels=y_train.sort_values().unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for as much as 19 target to be learned by our machine learning, an overall accuracy of 76% is quite good.\n",
    "\n",
    "#### *Train and test for predicting score*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_bal_train, x_bal_test, y_bal_train, y_bal_test = train_test_split(proms_df.loc[proms_df.title == \"balance\", proms_df.columns != \"score\"], \n",
    "proms_df[proms_df.title == \"balance\"].score, test_size=0.2, random_state=126)\n",
    "\n",
    "x_cal_train, x_cal_test, y_cal_train, y_cal_test = train_test_split(proms_df.loc[proms_df.title == \"call\", proms_df.columns != \"score\"], \n",
    "proms_df[proms_df.title == \"call\"].score, test_size=0.2, random_state=126)\n",
    "\n",
    "x_cl_train, x_cl_test, y_cl_train, y_cl_test = train_test_split(proms_df.loc[proms_df.title == \"confirmation-letter\", proms_df.columns != \"score\"], \n",
    "proms_df[proms_df.title == \"confirmation-letter\"].score, test_size=0.2, random_state=126)\n",
    "\n",
    "x_coo_train, x_coo_test, y_coo_train, y_coo_test = train_test_split(proms_df.loc[proms_df.title == \"coordination\", proms_df.columns != \"score\"], \n",
    "proms_df[proms_df.title == \"coordination\"].score, test_size=0.2, random_state=126)\n",
    "\n",
    "x_dai_train, x_dai_test, y_dai_train, y_dai_test = train_test_split(proms_df.loc[proms_df.title == \"daily\", proms_df.columns != \"score\"], \n",
    "proms_df[proms_df.title == \"daily\"].score, test_size=0.2, random_state=126)\n",
    "\n",
    "x_dat_train, x_dat_test, y_dat_train, y_dat_test = train_test_split(proms_df.loc[proms_df.title == \"data\", proms_df.columns != \"score\"], \n",
    "proms_df[proms_df.title == \"data\"].score, test_size=0.2, random_state=126)\n",
    "\n",
    "x_fol_train, x_fol_test, y_fol_train, y_fol_test = train_test_split(proms_df.loc[proms_df.title == \"follow-up\", proms_df.columns != \"score\"], \n",
    "proms_df[proms_df.title == \"follow-up\"].score, test_size=0.2, random_state=126)\n",
    "\n",
    "x_in_train, x_in_test, y_in_train, y_in_test = train_test_split(proms_df.loc[proms_df.title == \"input\", proms_df.columns != \"score\"], \n",
    "proms_df[proms_df.title == \"input\"].score, test_size=0.2, random_state=126)\n",
    "\n",
    "x_mai_train, x_mai_test, y_mai_train, y_mai_test = train_test_split(proms_df.loc[proms_df.title == \"mail\", proms_df.columns != \"score\"], \n",
    "proms_df[proms_df.title == \"mail\"].score, test_size=0.2, random_state=126)\n",
    "\n",
    "x_mee_train, x_mee_test, y_mee_train, y_mee_test = train_test_split(proms_df.loc[proms_df.title == \"meeting\", proms_df.columns != \"score\"], \n",
    "proms_df[proms_df.title == \"meeting\"].score, test_size=0.2, random_state=126)\n",
    "\n",
    "x_nav_train, x_nav_test, y_nav_train, y_nav_test = train_test_split(proms_df.loc[proms_df.title == \"net-asset-value\", proms_df.columns != \"score\"], \n",
    "proms_df[proms_df.title == \"net-asset-value\"].score, test_size=0.2, random_state=126)\n",
    "\n",
    "x_oth_train, x_oth_test, y_oth_train, y_oth_test = train_test_split(proms_df.loc[proms_df.title == \"other\", proms_df.columns != \"score\"], \n",
    "proms_df[proms_df.title == \"other\"].score, test_size=0.2, random_state=126)\n",
    "\n",
    "x_pro_train, x_pro_test, y_pro_train, y_pro_test = train_test_split(proms_df.loc[proms_df.title == \"prospect\", proms_df.columns != \"score\"], \n",
    "proms_df[proms_df.title == \"prospect\"].score, test_size=0.2, random_state=126)\n",
    "\n",
    "x_rev_train, x_rev_test, y_rev_train, y_rev_test = train_test_split(proms_df.loc[proms_df.title == \"review\", proms_df.columns != \"score\"], \n",
    "proms_df[proms_df.title == \"review\"].score, test_size=0.2, random_state=126)\n",
    "\n",
    "x_sr_train, x_sr_test, y_sr_train, y_sr_test = train_test_split(proms_df.loc[proms_df.title == \"siar\", proms_df.columns != \"score\"], \n",
    "proms_df[proms_df.title == \"siar\"].score, test_size=0.2, random_state=126)\n",
    "\n",
    "x_sp_train, x_sp_test, y_sp_train, y_sp_test = train_test_split(proms_df.loc[proms_df.title == \"siap\", proms_df.columns != \"score\"], \n",
    "proms_df[proms_df.title == \"siap\"].score, test_size=0.2, random_state=126)\n",
    "\n",
    "x_tra_train, x_tra_test, y_tra_train, y_tra_test = train_test_split(proms_df.loc[proms_df.title == \"transaction\", proms_df.columns != \"score\"], \n",
    "proms_df[proms_df.title == \"transaction\"].score, test_size=0.2, random_state=126)\n",
    "\n",
    "x_upd_train, x_upd_test, y_upd_train, y_upd_test = train_test_split(proms_df.loc[proms_df.title == \"update\", proms_df.columns != \"score\"], \n",
    "proms_df[proms_df.title == \"update\"].score, test_size=0.2, random_state=126)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Machine learning for prediction score*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_bal = CountVectorizer(min_df=5, ngram_range=(1,5)).fit(x_bal_train.remarks)\n",
    "model_naive_bal = MultinomialNB().fit(vect_bal.transform(x_bal_train.remarks), y_bal_train)\n",
    "\n",
    "vect_cal = CountVectorizer(min_df=5, ngram_range=(1,5)).fit(x_cal_train.remarks)\n",
    "model_naive_cal = MultinomialNB().fit(vect_cal.transform(x_cal_train.remarks), y_cal_train)\n",
    "\n",
    "vect_cl = CountVectorizer(min_df=5, ngram_range=(1,5)).fit(x_cl_train.remarks)\n",
    "model_naive_cl = MultinomialNB().fit(vect_cl.transform(x_cl_train.remarks), y_cl_train)\n",
    "\n",
    "vect_coo = CountVectorizer(min_df=5, ngram_range=(1,5)).fit(x_coo_train.remarks)\n",
    "model_naive_coo = MultinomialNB().fit(vect_coo.transform(x_coo_train.remarks), y_coo_train)\n",
    "\n",
    "vect_dai = CountVectorizer(min_df=5, ngram_range=(1,5)).fit(x_dai_train.remarks)\n",
    "model_naive_dai = MultinomialNB().fit(vect_dai.transform(x_dai_train.remarks), y_dai_train)\n",
    "\n",
    "vect_dat = CountVectorizer(min_df=5, ngram_range=(1,5)).fit(x_dat_train.remarks)\n",
    "model_naive_dat = MultinomialNB().fit(vect_dat.transform(x_dat_train.remarks), y_dat_train)\n",
    "\n",
    "vect_fol = CountVectorizer(min_df=5, ngram_range=(1,5)).fit(x_fol_train.remarks)\n",
    "model_naive_fol = MultinomialNB().fit(vect_fol.transform(x_fol_train.remarks), y_fol_train)\n",
    "\n",
    "vect_in = CountVectorizer(min_df=5, ngram_range=(1,5)).fit(x_in_train.remarks)\n",
    "model_naive_in = MultinomialNB().fit(vect_in.transform(x_in_train.remarks), y_in_train)\n",
    "\n",
    "vect_mai = CountVectorizer(min_df=5, ngram_range=(1,5)).fit(x_mai_train.remarks)\n",
    "model_naive_mai = MultinomialNB().fit(vect_mai.transform(x_mai_train.remarks), y_mai_train)\n",
    "\n",
    "vect_mee = CountVectorizer(min_df=5, ngram_range=(1,5)).fit(x_mee_train.remarks)\n",
    "model_naive_mee = MultinomialNB().fit(vect_mee.transform(x_mee_train.remarks), y_mee_train)\n",
    "\n",
    "vect_nav = CountVectorizer(min_df=5, ngram_range=(1,5)).fit(x_nav_train.remarks)\n",
    "model_naive_nav = MultinomialNB().fit(vect_nav.transform(x_nav_train.remarks), y_nav_train)\n",
    "\n",
    "vect_oth = CountVectorizer(min_df=5, ngram_range=(1,5)).fit(x_oth_train.remarks)\n",
    "model_naive_oth = MultinomialNB().fit(vect_oth.transform(x_oth_train.remarks), y_oth_train)\n",
    "\n",
    "vect_pro = CountVectorizer(min_df=5, ngram_range=(1,5)).fit(x_pro_train.remarks)\n",
    "model_naive_pro = MultinomialNB().fit(vect_pro.transform(x_pro_train.remarks), y_pro_train)\n",
    "\n",
    "vect_rev = CountVectorizer(min_df=5, ngram_range=(1,5)).fit(x_rev_train.remarks)\n",
    "model_naive_rev = MultinomialNB().fit(vect_rev.transform(x_rev_train.remarks), y_rev_train)\n",
    "\n",
    "vect_sr = CountVectorizer(min_df=5, ngram_range=(1,5)).fit(x_sr_train.remarks)\n",
    "model_naive_sr = MultinomialNB().fit(vect_sr.transform(x_sr_train.remarks), y_sr_train)\n",
    "\n",
    "vect_sp = CountVectorizer(min_df=5, ngram_range=(1,5)).fit(x_sp_train.remarks)\n",
    "model_naive_sp = MultinomialNB().fit(vect_sp.transform(x_sp_train.remarks), y_sp_train)\n",
    "\n",
    "vect_tra = CountVectorizer(min_df=5, ngram_range=(1,5)).fit(x_tra_train.remarks)\n",
    "model_naive_tra = MultinomialNB().fit(vect_tra.transform(x_tra_train.remarks), y_tra_train)\n",
    "\n",
    "vect_upd = CountVectorizer(min_df=5, ngram_range=(1,5)).fit(x_upd_train.remarks)\n",
    "model_naive_upd = MultinomialNB().fit(vect_upd.transform(x_upd_train.remarks), y_upd_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_bal = model_naive_bal.predict(vect_bal.transform(x_bal_test.remarks))\n",
    "pred_cal = model_naive_cal.predict(vect_cal.transform(x_cal_test.remarks))\n",
    "pred_cl = model_naive_cl.predict(vect_cl.transform(x_cl_test.remarks))\n",
    "pred_coo = model_naive_coo.predict(vect_coo.transform(x_coo_test.remarks))\n",
    "pred_dai = model_naive_dai.predict(vect_dai.transform(x_dai_test.remarks))\n",
    "pred_dat = model_naive_dat.predict(vect_dat.transform(x_dat_test.remarks))\n",
    "pred_fol = model_naive_fol.predict(vect_fol.transform(x_fol_test.remarks))\n",
    "pred_in = model_naive_in.predict(vect_in.transform(x_in_test.remarks))\n",
    "pred_mai = model_naive_mai.predict(vect_mai.transform(x_mai_test.remarks))\n",
    "pred_mee = model_naive_mee.predict(vect_mee.transform(x_mee_test.remarks))\n",
    "pred_nav = model_naive_nav.predict(vect_nav.transform(x_nav_test.remarks))\n",
    "pred_oth = model_naive_oth.predict(vect_oth.transform(x_oth_test.remarks))\n",
    "pred_pro = model_naive_pro.predict(vect_pro.transform(x_pro_test.remarks))\n",
    "pred_rev = model_naive_rev.predict(vect_rev.transform(x_rev_test.remarks))\n",
    "pred_sr = model_naive_sr.predict(vect_sr.transform(x_sr_test.remarks))\n",
    "pred_sp = model_naive_sp.predict(vect_sp.transform(x_sp_test.remarks))\n",
    "pred_tra = model_naive_tra.predict(vect_tra.transform(x_tra_test.remarks))\n",
    "pred_upd = model_naive_upd.predict(vect_upd.transform(x_upd_test.remarks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of balace               :  0.7697841726618705\n",
      "Accuracy of call                 :  0.7487367937528709\n",
      "Accuracy of confirmation-letter  :  0.927710843373494\n",
      "Accuracy of coordination         :  0.3287037037037037\n",
      "Accuracy of daily                :  0.6376146788990825\n",
      "Accuracy of data                 :  0.4613935969868173\n",
      "Accuracy of follow-up            :  0.6070175438596491\n",
      "Accuracy of input                :  0.455026455026455\n",
      "Accuracy of mail                 :  0.4434389140271493\n",
      "Accuracy of meeting              :  0.4352542372881356\n",
      "Accuracy of net-asset-value      :  0.8395904436860068\n",
      "Accuracy of other                :  0.46246396791577893\n",
      "Accuracy of prospect             :  0.7022222222222222\n",
      "Accuracy of review               :  0.3879849812265332\n",
      "Accuracy of siar                 :  0.8606811145510835\n",
      "Accuracy of siap                 :  0.7014925373134329\n",
      "Accuracy of transaction          :  0.5716272600834492\n",
      "Accuracy of update               :  0.6725595695618755\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of balance              : \", metrics.accuracy_score(y_bal_test, pred_bal))\n",
    "print(\"Accuracy of call                 : \", metrics.accuracy_score(y_cal_test, pred_cal))\n",
    "print(\"Accuracy of confirmation-letter  : \", metrics.accuracy_score(y_cl_test, pred_cl))\n",
    "print(\"Accuracy of coordination         : \", metrics.accuracy_score(y_coo_test, pred_coo))\n",
    "print(\"Accuracy of daily                : \", metrics.accuracy_score(y_dai_test, pred_dai))\n",
    "print(\"Accuracy of data                 : \", metrics.accuracy_score(y_dat_test, pred_dat))\n",
    "print(\"Accuracy of follow-up            : \", metrics.accuracy_score(y_fol_test, pred_fol))\n",
    "print(\"Accuracy of input                : \", metrics.accuracy_score(y_in_test, pred_in))\n",
    "print(\"Accuracy of mail                 : \", metrics.accuracy_score(y_mai_test, pred_mai))\n",
    "print(\"Accuracy of meeting              : \", metrics.accuracy_score(y_mee_test, pred_mee))\n",
    "print(\"Accuracy of net-asset-value      : \", metrics.accuracy_score(y_nav_test, pred_nav))\n",
    "print(\"Accuracy of other                : \", metrics.accuracy_score(y_oth_test, pred_oth))\n",
    "print(\"Accuracy of prospect             : \", metrics.accuracy_score(y_pro_test, pred_pro))\n",
    "print(\"Accuracy of review               : \", metrics.accuracy_score(y_rev_test, pred_rev))\n",
    "print(\"Accuracy of siar                 : \", metrics.accuracy_score(y_sr_test, pred_sr))\n",
    "print(\"Accuracy of siap                 : \", metrics.accuracy_score(y_sp_test, pred_sp))\n",
    "print(\"Accuracy of transaction          : \", metrics.accuracy_score(y_tra_test, pred_tra))\n",
    "print(\"Accuracy of update               : \", metrics.accuracy_score(y_upd_test, pred_upd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although there are machine learning with a performance of lower than 50%, the overall accuracy of the prediction is still quite good. With further data accumulation, we can adjust our machine learning to improve the overall accuracy in the future."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "athena",
   "language": "python",
   "name": "athena"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
